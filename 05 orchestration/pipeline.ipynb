{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "608ffb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from airflow import DAG\n",
    "from airflow.operators.python import PythonOperator\n",
    "from airflow.operators.bash import BashOperator\n",
    "\n",
    "# sys.path lists directories that Python searches for modules to import\n",
    "sys.path.append('..')\n",
    "import extract\n",
    "import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d228cc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_args = {\n",
    "    'owner': 'airflow',\n",
    "    'depends_on_past': False,\n",
    "    'start_date': datetime(2024, 1, 1),\n",
    "    'email_on_failure': False,\n",
    "    'email_on_retry': False,\n",
    "    'retries': 1,\n",
    "    'retry_delay': timedelta(minutes=5),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5444cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_directories():\n",
    "    \"\"\"Create necessary data directories if they don't exist.\"\"\"\n",
    "    directories = [\n",
    "        'data/raw',\n",
    "        'data/datalake',\n",
    "        'data/postgres',\n",
    "        'data/postgres/vol-pgadmin_data',\n",
    "        'data/postgres/vol-pgdata',\n",
    "    ]\n",
    "    \n",
    "    for directory in directories:\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "        print(f\"Created directory: {directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbae12b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_extract_load():\n",
    "    \"\"\"Run the extract and load process.\"\"\"\n",
    "    extract.main()\n",
    "    load.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138d58f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with DAG(\n",
    "    'pipeline',\n",
    "    default_args=default_args,\n",
    "    description='Sales Data ELT Pipeline',\n",
    "    schedule='@daily',\n",
    "    catchup=False,\n",
    ") as dag:\n",
    "\n",
    "    create_directories = PythonOperator(\n",
    "        task_id='create_directories',\n",
    "        python_callable=create_data_directories,\n",
    "    )\n",
    "\n",
    "    create_database = BashOperator(\n",
    "        task_id='create_database',\n",
    "        bash_command='docker-compose up || true',\n",
    "    )\n",
    "\n",
    "    run_elt = PythonOperator(\n",
    "        task_id='run_extract_load',\n",
    "        python_callable=run_extract_load,\n",
    "    )\n",
    "\n",
    "    run_dbt_model = BashOperator(\n",
    "    task_id='run_dbt_model',\n",
    "    bash_command='dbt run --models ../04\\ transform/'\n",
    "    )\n",
    "\n",
    "    # Set task dependencies\n",
    "    create_directories >> create_database >> run_elt >> run_dbt_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
